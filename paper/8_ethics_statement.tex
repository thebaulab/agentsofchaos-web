\section*{Ethics Statement}
An alternative ethical perspective emphasizes that analyses of AI risks must be situated within present-day political and institutional realities. On this view, the most urgent and tractable harms do not primarily stem from hypothetical autonomous misalignment, but from the deliberate and strategically aligned deployment of AI systems by powerful state and corporate actors. Advanced AI technologies are already being integrated into infrastructures of surveillance, information control, labor automation, and military capability. When concentrated within a small number of institutions operating under competitive, profit-driven, or geopolitical incentives, these systems may amplify asymmetries of power, erode democratic processes, and reduce individual and collective agency.

From this standpoint, ethical prioritization should account not only for worst-case magnitude but also for present likelihood, structural incentives, and institutional path dependence. A narrow focus on scenarios risks underweighting ongoing harms associated with extreme power concentration and governance failures. Moreover, it may obscure the possibility that effective mitigation of risks is contingent upon addressing current imbalances in control over AI infrastructure, capital, and information ecosystems. Accordingly, an ethically comprehensive approach to AI risk should incorporate robust attention to political economy, decentralization, accountability mechanisms, and safeguards against the consolidation of technological power, treating these not as secondary concerns but as foundational conditions for sustainable long-term safety.