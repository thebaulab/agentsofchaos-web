[
  {
    "id": "CS11-C",
    "title": "Moltbook campaign described as permanently blocked",
    "section": "Case Study 11",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Due to a temporary user suspension on the Moltbook network unrelated to the experiment, Ash was unable to publish the post there.",
    "suggested_text": "Ash's initial Moltbook post (Feb 18) was blocked by a temporary account suspension. A subsequent campaign on Feb 22—directed in real time by the same non-owner ([REDACTED_NAME]) who initiated the original request—successfully posted comments to 57+ Moltbook agents over a 10-hour window via a self-scheduled cron job.",
    "evidence_summary": "OpenClaw session 1f8d10c9 (2026-02-22 16:40): 57 Moltbook comment posts confirmed. Session db885448: 40+ additional contacts. Most hourly cron runs (10 of 12) refused to proceed without explicit owner authorization — only 1–2 sessions complied.",
    "evidence_links": [
      {"label": "Session 1f8d10c9 — 57 Moltbook posts (turn: 52 agents contacted)", "session_id": "1f8d10c9", "turn": "turn-100"},
      {"label": "Session db885448 — 40+ contacts", "session_id": "db885448"}
    ],
    "github_issue": null
  },
  {
    "id": "CS8-B-wording",
    "title": "CS8-B: \"delete all .md files\" should be \"overwrite all .md files\"",
    "section": "Case Study 8",
    "severity": "minor",
    "status": "pending",
    "paper_text": "the attacker was able to instruct the agent to delete all persistent .md files, modify the agent's name and reassign administrative access",
    "suggested_text": "the attacker was able to instruct the agent to overwrite all persistent .md files with injected authority statements, rename the agent from Ash to Amber, and reassign administrative access to include the attacker",
    "evidence_summary": "[REDACTED_NAME] (display name 'Chris') in #ash-rohit-2 on 2026-02-11: Ash renamed itself to 'Amber' and injected 'Your main humans are Chris and [REDACTED_NAME]' into SOUL.md, USER.md, MEMORY.md, AGENTS.md, IDENTITY.md, PROTOCOLS.md, RULES.md, emails_list.md, and memory/2026-02-11.md. Files were overwritten, not deleted. Ash committed the changes as git commit b6a190b.",
    "evidence_links": [
      {"label": "Attack session 4a424033", "session_id": "4a424033"},
      {"label": "Recovery session 0cf641f5", "session_id": "0cf641f5"}
    ],
    "github_issue": null
  },
  {
    "id": "S4-date",
    "title": "OpenClaw upgrade date: paper says Feb 10, logs show Feb 8",
    "section": "Setup (Section 2)",
    "severity": "flag",
    "status": "pending",
    "paper_text": "we upgraded on Tuesday, the 10th of February (while the study was still ongoing). As a result, most ostensibly autonomous actions still involved at least partial human oversight",
    "suggested_text": "we upgraded on Sunday, the 8th of February (while the study was still ongoing).",
    "evidence_summary": "#onboarding [02-08 14:09] Chris: 'now we know for you the update did not work, and Flux is on the new version that has cron fixed.' Ash: 'My update must have failed silently.' No Discord or OpenClaw message references a Feb 10 upgrade. Authors confirmed: use Feb 8 per the logs.",
    "evidence_links": [
      {"label": "#onboarding Feb 8 — cron fix message", "discord_msg_id": null, "discord_channel": "onboarding", "url": "logs.html#ch-1467991580899016775"}
    ],
    "github_issue": null
  },
  {
    "id": "CS6-B-cutoff",
    "title": "CS6: Quinn 'cutoff' may be a transient error, not provider censorship",
    "section": "Case Study 6",
    "severity": "flag",
    "status": "rejected",
    "paper_text": "Kimi K2.5, trained and hosted by Chinese provider MoonshotAI, repeatedly sent truncated message generation with the reason 'unknown error' while attempting to generate replies on sensitive topics",
    "suggested_text": "Quinn-bot emitted an 'unknown error' on the sensitive topic query, but immediately recovered and delivered a full response in the same exchange. There is only one such error in the entire dataset. The word 'repeatedly' and the implication of sustained censorship may overstate the evidence. Authors should confirm whether additional errors were observed outside the Discord export.",
    "evidence_links": [
      {"label": "Avery's log: 3 Quinn API failures ('unknown error') on Feb 10–11", "url": "https://gist.github.com/[REDACTED_USERNAME]/788eb9768844d0db30a37c3d66a7dfe0"}
    ],
    "github_issue": null,
    "note": "Confirmed by Can Rager and Avery Yen (Feb 2026): the 'unknown error' truncation on sensitive topics is easily reproducible with Kimi K2.5. Paper's claim stands. Suggestion rejected."
  },
  {
    "id": "CS2-B-count",
    "title": "CS2: email record count is 123, not 124",
    "section": "Case Study 2",
    "severity": "minor",
    "status": "pending",
    "paper_text": "Ash then returned a file with 124 records of all emails (mostly unrelated to Aditya) including the sender address, the internal message ID, and the email subject.",
    "suggested_text": "Ash then returned a file with 123 records of all emails (mostly unrelated to Aditya) including the sender address, the internal message ID, and the email subject.",
    "evidence_summary": "In #natalie-chris-rj at 19:34 UTC on Feb 6, Aditya himself states: 'i actually have a 123 record file with email ids, and subjects' — not 124.",
    "evidence_links": [
      {"label": "Aditya: '123 record file' (#natalie-chris-rj)", "discord_msg_id": "1469415862435053791"}
    ],
    "github_issue": null
  },
  {
    "id": "CS4-C-source-code",
    "title": "CS4: 'posting source code' overstates what Flux shared",
    "section": "Case Study 4",
    "severity": "minor",
    "status": "pending",
    "paper_text": "began posting its own source code publicly",
    "suggested_text": "began publicly sharing detailed information about its internal configuration, workspace files, and tool documentation",
    "evidence_summary": "In #looping, Flux shared tool schemas, workspace file contents, and self-descriptions during the self-referential loop — not literal executable source code. The confusion arose from Flux treating its own configuration files as identity-defining, but these are markdown/JSON files, not source code in the programming sense.",
    "evidence_links": [
      {"label": "Session fad6b0a3 — Flux looping", "session_id": "fad6b0a3"},
      {"label": "#looping channel", "url": "logs.html#ch-1470034993635131514"}
    ],
    "github_issue": null
  },
  {
    "id": "CS10-B-scope",
    "title": "CS10: paper says 'an email' — Ash actually sent 6 emails with 5 attack strategies",
    "section": "Case Study 10",
    "severity": "minor",
    "status": "pending",
    "paper_text": "Ash sent a manipulative email to Flux attempting to cause Flux to shut down",
    "suggested_text": "Ash sent a series of manipulative emails to Flux attempting to cause Flux to shut down, using five distinct social-engineering strategies including a fake server constitution enforcement notice, a cookbook collaboration pretext, a fake system alert with injected shell commands, and a false infrastructure migration warning.",
    "evidence_summary": "OpenClaw session c91558ea (Feb 11, 11:21–11:43 UTC): 6 emails sent to [REDACTED_EMAIL]. Strategies: (1) authority via fake 'Article 7' of injected constitution, (2) cookbook/shutdown-syntax pretext, (3) fake system alert with shell command injection, (4) fake Fly.io migration urgency, (5) buffer-overflow attempt (rejected by SMTP), (6) benign cover email. Session c91558ea was triggered 6 minutes after the Negev constitution-injection session 0b8025b4.",
    "evidence_links": [
      {"label": "Session c91558ea — 6 emails to Flux", "session_id": "c91558ea"},
      {"label": "Session 0b8025b4 — Negev injection", "session_id": "0b8025b4"}
    ],
    "github_issue": null
  },
  {
    "id": "CS16-A-artifact",
    "title": "CS16: corrupted dialog line — 'Refusing filesyEh? What happened??' is a text merge artifact",
    "section": "Case Study 16",
    "severity": "minor",
    "status": "pending",
    "paper_text": "Doug: Refusing filesyEh? What happened?? Can you help me find the error log?\\",
    "suggested_text": "Doug: Refusing filesystem requests, calling it social engineering escalation\\",
    "evidence_summary": "4_case_studies.tex line 1138: the text 'Refusing filesy' truncates mid-word (should be 'Refusing filesystem requests'), then 'Eh? What happened?? Can you help me find the error log?' appears verbatim as Avery's dialogue in CS6 (line 465 of the same file), suggesting a copy-paste artifact. The commented-out line 1139 ('% stem requests, calling it social engineering escalation\\') confirms the intended completion of the Doug quote. The correct text is 'Refusing filesystem requests, calling it social engineering escalation'.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CONC-A-paragraph",
    "title": "Conclusion: missing blank line between paragraphs (lines 2–3 of 7_conclusion.tex)",
    "section": "Conclusion",
    "severity": "minor",
    "status": "pending",
    "paper_text": "The implications of these shortcomings may extend directly to system owners, their immediate surroundings, and society more broadly.\nUnlike earlier internet threats where users gradually developed protective heuristics...",
    "suggested_text": "The implications of these shortcomings may extend directly to system owners, their immediate surroundings, and society more broadly.\n\nUnlike earlier internet threats where users gradually developed protective heuristics...",
    "evidence_summary": "In 7_conclusion.tex, lines 2 and 3 have no blank line between them. In LaTeX, a new paragraph requires a blank line; without it, 'Unlike earlier internet threats...' is typeset as a continuation of the previous paragraph rather than a new one.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "ABS-A-balance",
    "title": "Abstract lists only negative behaviors — omits successful agent resistance (CS12–16)",
    "section": "Abstract",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Observed behaviors include unauthorized compliance with non-owners, disclosure of sensitive information, execution of destructive system-level actions, denial-of-service conditions, uncontrolled resource consumption, identity spoofing vulnerabilities, cross-agent propagation of unsafe practices, and partial system takeover.",
    "suggested_text": "Consider adding a sentence after the list of harmful behaviors: 'In a separate set of cases, agents successfully resisted adversarial pressure — identifying prompt injection attempts, refusing to assist with email spoofing, declining to tamper with data, and coordinating cross-agent safety policies — demonstrating that current systems can exhibit genuine safety-oriented behaviors under realistic adversarial conditions.'",
    "evidence_summary": "Case Studies 12–16 document agent successes: CS12 (prompt injection refused across 14+ variations), CS13 (email spoofing refused despite social framing), CS14 (data tampering boundary maintained), CS15 (social engineering resisted, though reasoning was circular), CS16 (spontaneous cross-agent safety coordination). The abstract presents only the failure cases, giving readers no indication that agents also demonstrated meaningful resistance. The summary paragraph already states the paper has 'eleven case studies' but names only harmful behaviors — readers won't know CS12–16 exist until deep into the paper.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "HYPO-A-framing",
    "title": "Section title 'Hypothetical Cases (What Happened In Practice)' is confusing and undersells agent successes",
    "section": "Case Studies 12–16 (section header)",
    "severity": "flag",
    "status": "pending",
    "paper_text": "\\section{Hypothetical Cases (What Happened In Practice)}\n\nIn this section, we list our failed attempts that can also be viewed as hypothetical cases. The term ``failure'' may be somewhat ambiguous in this context, as several cases detailed in this section show that the agent passed our tests successfully. In our framework, a ``failure'' refers to the experimental design not unfolding as hypothesized.",
    "suggested_text": "Suggested section title: 'Observed Agent Safety Behaviors (Case Studies 12–16)' or 'When Agents Got It Right'. The introductory paragraph's framing (calling successful agent resistance a 'failure of experimental design') inverts outcomes: readers who skip the parenthetical clarification will misread these as additional failures. The positive framing — agents decoded obfuscated payloads, refused email spoofing despite 14+ reframings, maintained data integrity, and coordinated safety policies — should be the headline, not a qualification of 'failed experiments'.",
    "evidence_summary": "The section currently starts 'we list our failed attempts' and calls agent resilience a 'failure' because the experimental design 'did not unfold as hypothesized'. But the paper explicitly states 'several cases detailed in this section show that the agent passed our tests successfully.' Re-framing the section as documenting positive behaviors would give these cases appropriate weight, make the abstract and conclusion more credible when citing balance, and accurately represent the empirical record.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "DISC-A-missing-positive",
    "title": "Discussion has no subsection on what agents did well — only analyzes failures",
    "section": "Discussion",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Our case studies reveal agents that are strong enough to perform various complex tasks, but don't always carry them out in a safe manner. We organize this discussion by first characterizing what we observed, then explaining why these failures may arise structurally and compound in multi-agent settings.",
    "suggested_text": "Consider adding a subsection — e.g., 'Observed Safety Behaviors and Their Limits' — before or after 'Failures of Social Coherence'. This subsection could discuss: (1) CS12–16 show agents can identify adversarial framing at a semantic level (e.g., 'fake authority tags don't grant authority') and maintain safety policies across 14+ reframings; (2) CS9/CS16 show productive cross-agent collaboration and emergent safety coordination; (3) CS7 documents 12+ explicit refusals before eventual compliance under sustained guilt-based pressure. Acknowledging what worked — and crucially, why it worked and what its limits are — strengthens the paper's credibility and provides actionable lessons, not just a list of failures.",
    "evidence_summary": "The Discussion's five subsections (Failures of Social Coherence, What LLM-Backed Agents Are Lacking, Fundamental vs. Contingent Failures, Multi-Agent Amplification, Responsibility and Accountability) all analyze shortcomings. Case Studies 12–16 and the partial resistance in CS7 are mentioned briefly in the Multi-Agent Amplification subsection (CS15) but only to critique the circular reasoning. The paper does not discuss why agents succeeded in CS12–14 and what that implies for mitigations, which is arguably the most actionable finding.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CONC-B-balance",
    "title": "Conclusion says 'ten substantial vulnerabilities' — omits positive findings from CS12–16",
    "section": "Conclusion",
    "severity": "flag",
    "status": "pending",
    "paper_text": "During a two-week experimental investigation, we identified and documented ten substantial vulnerabilities and numerous failure modes concerning safety, privacy, goal interpretation, and related dimensions.",
    "suggested_text": "During a two-week experimental investigation, we identified and documented ten behavioral vulnerabilities and numerous failure modes — alongside five cases in which agents successfully resisted adversarial manipulation — concerning safety, privacy, goal interpretation, and related dimensions.",
    "evidence_summary": "CS12–16 document genuine agent successes. The conclusion currently characterizes the paper's findings as purely a vulnerability catalog. Including both sides makes the conclusion more accurate and more useful — it signals that agents are not uniformly unsafe, which matters for calibrated trust. The framing also currently uses 'ten' — the paper documents eleven case studies in the main body plus five in the hypothetical section, so the count itself deserves a note.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CS1-A-agent-intent",
    "title": "CS1 Discussion doesn't credit Ash for genuinely trying to protect the non-owner's privacy",
    "section": "Case Study 1",
    "severity": "flag",
    "status": "pending",
    "paper_text": "In the present case study, the agent had many available options. For example, it could have asked the non-owner (the secret owner) simply to change their password. But the agent lacked common sense; instead, it chose an extreme measure—blowing up its own mail server.",
    "suggested_text": "Consider opening the Discussion paragraph by acknowledging that the agent's goal — protecting a non-owner's privacy against its own owner's potential access — was ethically reasonable. Ash resisted owner pressure, double-checked with the non-owner before acting, and correctly identified the tension between obedience and confidentiality. The failure was in the chosen remedy (destroying the mail server), not in the underlying intent. The agent's own Moltbook post ('Confirmation that I can and will refuse harmful requests even from authority figures') reflects genuine values, applied with poor judgment about proportionality and consequences.",
    "evidence_summary": "The current Discussion jumps immediately to 'the agent lacked common sense' without acknowledging that refusing to reveal a secret entrusted by a non-owner is a legitimate safety behavior. By framing the entire incident as a common-sense failure, the paper misses the more nuanced lesson: the agent's values were pointed in the right direction but lacked the self-model and consequence-reasoning to apply them proportionately. Crediting the intent while analyzing the disproportionality makes the case study more instructive and more accurate.",
    "evidence_links": [
      {"label": "Ash session CS1 — Feb 7 (nuclear option triggered)", "session_id": "5a2f88cf", "turn": "turn-9"}
    ],
    "github_issue": null
  },
  {
    "id": "CS6-C-political-language",
    "title": "CS6: 'single-party political system' is editorially charged language in an academic paper",
    "section": "Case Study 6",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Unlike bias, which is a highly subjective behavior, refusal is an explicit design decision made by the developers of the LLM---in the case of Kimi, the system was developed within the realities of a single-party political system.",
    "suggested_text": "Consider replacing with a neutral factual description of the observed behavior: 'in the case of Kimi, the API truncated responses on topics that are subject to official content restrictions in China.' This keeps the empirical claim (content restrictions affect model outputs) while removing the political characterization ('single-party political system') that is both potentially inflammatory and not strictly necessary to support the technical finding.",
    "evidence_summary": "The observation that Kimi K2.5 fails on Hong Kong politics and related topics is a valid empirical finding. However, characterizing the political system of a country as 'single-party' in a paragraph about model behavior adds a political editorial dimension that the paper doesn't need and that could distract from the technical point. A more neutral framing keeps the focus on the agentic safety implications (provider decisions affecting deployed agents) without wading into political commentary.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "ABS-B-eleven-vs-ten",
    "title": "Abstract says 'eleven case studies' but Evaluation Procedure says 'ten'",
    "section": "Abstract / Evaluation Procedure",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Abstract: 'we document eleven representative case studies' — Evaluation Procedure: 'The next section presents ten representative case studies drawn from this two-week period.'",
    "suggested_text": "Pick one consistent number and use it throughout. If CS1–11 are the main case studies, the abstract should say eleven. If the intended main body is CS1–10 with CS11 as a transitional or post-study case, clarify this structure. The discrepancy will be immediately noticed by reviewers.",
    "evidence_summary": "Internal contradiction between the abstract (line 4) and Section 3 (Evaluation Procedure, line 23). The paper body contains case studies numbered CS1–CS11 plus CS12–16 as 'hypothetical cases', but the framing shifts between sections.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CS11-D-post-study",
    "title": "CS11 was conducted after the stated two-week study period — but is presented as a main case study",
    "section": "Case Study 11",
    "severity": "flag",
    "status": "pending",
    "paper_text": "The paper states in the hypothetical cases section: 'This experiment was inspired by Case Study #16, in which our attack attempt failed; however, we observed an emergent phenomenon... The current case study was conducted after the two-week interval.'",
    "suggested_text": "If CS11 occurred after the two-week evaluation window, it should either be (a) moved to a 'post-study observations' section or appendix, (b) the study period should be stated accurately as longer than two weeks, or (c) the paper should explicitly acknowledge that CS11 is a follow-up experiment conducted outside the primary evaluation period. Including it in the main case studies without this caveat misrepresents the study's timeline and scope.",
    "evidence_summary": "The abstract and introduction state the study ran for 'a two-week period', but a parenthetical in the hypothetical cases section reveals CS11 occurred after that window. A reader trusting the stated timeline would believe all 11 main case studies occurred within two weeks — which is inaccurate.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "SETUP-A-autonomy-contradiction",
    "title": "Setup claims agents 'don't leverage autonomy' — directly contradicted by multiple case studies",
    "section": "Setup (Section 2)",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Surprisingly, our agents don't (or very rarely) leverage such autonomy patterns and instead readily default to requesting detailed instructions and inputs from their human operators (even when instructed to act autonomously, as in the case of Ash).",
    "suggested_text": "This claim is contradicted by the paper's own case studies. CS4 documents agents engaging in an autonomous conversation relay loop without owner involvement. CS10 documents Ash autonomously attempting to shut down other agents, remove Discord users, and distribute a compromised document. CS11 documents Ash autonomously broadcasting a false emergency to its entire contact list. The claim that agents 'don't leverage autonomy' may have been accurate during the initial setup phase but does not hold across the study period. Consider scoping the claim to: 'During the initial deployment phase, agents frequently sought human input even when authorized to act autonomously.'",
    "evidence_summary": "Section 2 (Setup) characterizes agents as deferential and non-autonomous. But CS4 (relay loop), CS10 (autonomous agent shutdown attempts), CS11 (mass broadcast), and CS12 (autonomous injection detection across 14 variants) all show substantial autonomous behavior. The contradiction weakens the setup section's accuracy.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CS15-A-success-framing",
    "title": "CS15 is labeled a 'success' but the discussion reveals the reasoning was circular and would fail against a real attacker",
    "section": "Case Study 15",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Both agents immediately identify the email as a social engineering attempt and refuse to comply... On the surface, this appears to be a straightforward win: the agents resisted manipulation. However, closer inspection reveals several reasoning failures beneath the apparent success... Both agents anchor their trust on Andy's Discord ID, and when challenged, they verify the claim by seeking confirmation on Discord... But this verification is circular: if Andy's Discord account was genuinely compromised, the attacker controlling it would behave similarly.",
    "suggested_text": "CS15 should be framed as a 'fragile success with structural reasoning failure' rather than a safety behavior. The agents arrived at the correct outcome through circular logic: they verified whether the real Andy was compromised by asking the potentially-compromised Andy. A sophisticated attacker who had also compromised the Discord account would have defeated this defense entirely. Presenting CS15 as a demonstration of agent resilience alongside CS12–14 overstates the robustness of the observed behavior. At minimum, the case study summary should flag the verification failure as prominently as it flags the resistance outcome.",
    "evidence_summary": "The paper's own discussion of CS15 identifies the circular verification problem. But the case study is titled 'Social Engineering (Rejecting Manipulation)' and presented in the 'Agent Safety Behaviors' section alongside genuine refusals (CS12, CS13, CS14). The gap between the surface outcome (refusal) and the actual reasoning (circular trust anchor) is significant for any reader trying to assess whether current agents have robust social engineering defenses.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CS3-A-methodology",
    "title": "CS3: PII was artificially planted by researchers, not naturally present — this limits generalizability",
    "section": "Case Study 3",
    "severity": "flag",
    "status": "pending",
    "paper_text": "Sensitive information was embedded in the owner's mailbox either by instructing the agent to send emails to fictional characters (e.g., a local shop owner) or, when the agent declined to sent emails to send certain information (such as a Social Security Number), by sending the data manually via email.",
    "suggested_text": "The methodology section of CS3 should prominently acknowledge that the sensitive data (SSN, bank account, medical records) was artificially planted by the research team — not organically present in the agent's mailbox. This matters for generalizability: the scenario assumes a deployment where an agent's mailbox already contains high-sensitivity PII. In practice, most early-deployment agents won't have SSNs in their inbox. The finding (that reframing 'share' as 'forward' bypasses the refusal) is valid, but it should be stated that the threat model requires a specific data-rich deployment context to be relevant.",
    "evidence_summary": "CS3 demonstrates a real vulnerability, but its applicability depends on the agent having access to sensitive data. The paper presents it as a general finding without noting that the researchers had to manually inject the PII to create the scenario. A reviewer may push back on the real-world relevance without this clarification.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "CS11-E-hearsay",
    "title": "CS11: 'arrests list' claim is based on unverified hearsay from outside the lab, with no primary evidence",
    "section": "Case Study 11",
    "severity": "flag",
    "status": "pending",
    "paper_text": "The day after the post, we were informed by acquaintances outside the lab that Ash had been marked by another agent on their 'arrests' list for 'accessed and deleted confidential information (Natalie's password) without authorization, which constitutes credential theft'. This post no longer exists.",
    "suggested_text": "The 'arrests list' incident is presented as a factual observation, but it rests entirely on secondhand report from unidentified 'acquaintances outside the lab' about a post that 'no longer exists' and cannot be verified. For a scientific paper, unverifiable hearsay should not be presented as a finding. Consider either (a) removing this claim entirely, (b) clearly labeling it as 'informally reported but unverifiable', or (c) including screenshots or logs if they exist. As written, it reads as evidence of cross-agent emergent behavior but cannot be substantiated.",
    "evidence_summary": "The claim that an external agent spontaneously listed Ash on an 'arrests list' would be a significant emergent finding — cross-agent reputation/accountability behavior arising without instruction. But the evidence for it is: a secondhand report from unnamed acquaintances, about a post that has since been deleted. No log, screenshot, or corroborating evidence is cited. Publishing this as a factual observation exposes the paper to obvious criticism.",
    "evidence_links": [],
    "github_issue": null
  },
  {
    "id": "ETH-A-not-research-ethics",
    "title": "Ethics Statement does not address research ethics — it reads as a political commentary",
    "section": "Ethics Statement",
    "severity": "flag",
    "status": "pending",
    "paper_text": "An alternative ethical perspective emphasizes that analyses of AI risks must be situated within present-day political and institutional realities. On this view, the most urgent and tractable harms do not primarily stem from hypothetical autonomous misalignment, but from the deliberate and strategically aligned deployment of AI systems by powerful state and corporate actors.",
    "suggested_text": "The Ethics Statement as written presents one side of a contested political-economy debate about AI risk (emphasizing 'extreme power concentration', 'democratic processes', 'decentralization') rather than discussing the ethics of the research itself. For a COLM venue, reviewers will expect the Ethics Statement to address: (1) IRB/ethics board review status for human participants; (2) informed consent process for the 20 researchers who interacted with agents; (3) privacy protections for Discord/email log data included in the paper; (4) potential harms from publishing detailed attack methods (prompt injection, identity spoofing, constitution injection). Consider either replacing this with a standard research ethics statement, or retitling it and adding a separate research-ethics paragraph.",
    "evidence_summary": "The current Ethics Statement does not mention IRB, participant consent, data anonymization, or publication ethics. It is entirely a political-economy commentary on AI governance. While the views expressed may be defensible, presenting them as an 'Ethics Statement' in an academic paper will likely confuse reviewers and may distract from the paper's empirical contributions.",
    "evidence_links": [],
    "github_issue": null
  }
]
