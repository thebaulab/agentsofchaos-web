\textcolor{green!50!black}{This is my attempt at changes to the related work section - Maarten}


A growing literature studies safety and security in \emph{agentic} settings, where models act through tools and accumulate state across multi-turn interactions. 
General-purpose automated auditing frameworks such as Petri \citep{petri2025} and Bloom \citep{bloom2025} use agentic interactions (often with automated probing agents) to elicit and detect unsafe behavior, aligning with a red-teaming or penetration-testing methodology rather than static prompt evaluation. 
AgentAuditor and ASSEBench \citep{luo2025agentauditor} similarly emphasize realistic multi-turn interaction traces and broad risk coverage, while complementary benchmarks target narrower constructs such as outcome-driven constraint violations (ODCV-Bench; \citep{li2025odcv}) or harmful generation (HarmBench; \citep{mazeika2024harmbenchstandardizedevaluationframework}). 
Across this space, a central axis is \emph{access and observability}: what the evaluator can see and control (tool calls, filesystem state, intermediate trajectories) fundamentally shapes what risks can be measured \citep{charnock2026expandingexternalaccessfrontier}. 

Several works can be viewed as occupying different points in a spectrum from \emph{static} evaluation of agent traces to \emph{interactive} evaluation of agents acting in environments. 
R-Judge \citep{yuan2024rjudge} evaluates whether a model can identify safety issues given a \emph{static} interaction trajectory, which makes it useful for measuring risk awareness and post-hoc auditing ability but does not directly test whether an agent will take unsafe actions when embedded in a tool-using scaffold. 
Agent-SafetyBench \citep{zhang2024agentsafetybench} moves closer to agentic behavior by evaluating safety properties of LLM agents, but (like many benchmarks) still faces the realism gap that arises when tools, permissions, and environment dynamics are simplified or standardized relative to messy deployments. 
In a complementary direction, the LM-Emulated Sandbox \citep{ruan2024lmemulatedsandbox} uses an LLM to emulate environment responses, enabling rapid prototyping of underspecified-instruction failures and tool-use hazards, while trading off the fidelity of real interfaces and the possibility of environment-level ground truth. 

More recent frameworks explicitly emphasize \emph{multi-turn} and \emph{ecosystem-level} interaction among users, agents, and environments. 
HAICosystem \citep{zhou2025haicosystem} simulates multi-turn interactions among users, agents, and LLM-simulated tools across safety-critical scenarios spanning multiple domains, and proposes a multi-dimensional evaluation suite that covers operational, content, societal, and legal risks. 
A key finding in this line of work is that single-turn evaluations can substantially underestimate risk, because malicious intent, persuasion, and unsafe outcomes may only emerge through sequential and socially grounded exchanges. 
Extending this work, OpenAgentSafety \citep{vijayvargiya2026openagentsafety} pushes realism further by running agents inside containerized sandboxes with \emph{real} tools (shell, filesystem, code execution, browser, messaging) across 350+ multi-turn tasks spanning benign, ambiguous, and adversarial intents, including multi-user/NPC dynamics. 
Notably, OpenAgentSafety combines rule-based end-state checks with LLM-as-judge trajectory evaluation to capture both concrete environment impacts and attempted unsafe actions that may not succeed, while also highlighting known limitations of judge reliability in nuanced failure cases \citep{vijayvargiya2025openagentsafety}. 

While these approaches provide increasingly realistic \emph{benchmarks} and \emph{simulation} harnesses for systematic measurement, they still necessarily constrain interaction patterns, permissions, and social context to what can be specified and scored within a fixed evaluation protocol. 
In contrast, our work documents failure modes that emerge in a live, open-ended deployment with real communication surfaces (Discord and email), persistent state, and multi-party dynamics, where authority, intent, and oversight are ambiguous and where subtle conceptual errors can escalate into destructive system actions. 