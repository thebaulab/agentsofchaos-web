@misc{time-horizon-1-1,
title = {Time Horizon 1.1},
author = {METR},
howpublished = {\url{https://metr.org/blog/2026-1-29-time-horizon-1-1/}},
year = {2026},
month = {01},
}
@inproceedings{vijjini2025exploring,
  title={Exploring safety-utility trade-offs in personalized language models},
  author={Vijjini, Anvesh Rao and Chowdhury, Somnath Basu Roy and Chaturvedi, Snigdha},
  booktitle={Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={11316--11340},
  year={2025}
}

@misc{bhatia2025valuedriftstracingvalue,
      title={Value Drifts: Tracing Value Alignment During LLM Post-Training}, 
      author={Mehar Bhatia and Shravan Nayak and Gaurav Kamath and Marius Mosbach and Karolina Stańczak and Vered Shwartz and Siva Reddy},
      year={2025},
      eprint={2510.26707},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2510.26707}, 
}

@inproceedings{Vaswani+2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}
@inproceedings{zhou2025haicosystem,
  title={HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions},
  author={Zhou, Xuhui and Kim, Hyunwoo and Brahman, Faeze and Jiang, Liwei and Zhu, Hao and Lu, Ximing and Xu, Frank and Lin, Bill Yuchen and Choi, Yejin and Mireshghallah, Niloofar and Le Bras, Ronan and Sap, Maarten},
  booktitle={COLM},
  year={2025},
  url={http://arxiv.org/abs/2409.16427}
}
@inproceedings{vijayvargiya2026openagentsafety,
  title={OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety},
  author={Vijayvargiya, Sanidhya and Soni, Aditya Bharat and Zhou, Xuhui and Wang, Zora Zhiruo and Dziri, Nouha and Neubig, Graham and Sap, Maarten},
  year={2026},
  booktitle={ICLR},
  url={https://arxiv.org/abs/2507.06134}
}
@article{yuan2024rjudge,
  title={R-judge: Benchmarking safety risk awareness for llm agents},
  author={Yuan, Tongxin and He, Zhiwei and Dong, Lingzhong and Wang, Yiming and Zhao, Ruijie and Xia, Tian and Xu, Lizhen and Zhou, Binglin and Li, Fangqi and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2401.10019},
  year={2024}
}

@inproceedings{ruan2024lmemulatedsandbox,
  title={Identifying the risks of lm agents with an lm-emulated sandbox},
  author={Ruan, Yangjun and Dong, Honghua and Wang, Andrew and Pitis, Silviu and Zhou, Yongchao and Ba, Jimmy and Dubois, Yann and Maddison, Chris J and Hashimoto, Tatsunori},
  booktitle={ICLR},
  year={2024}
}
@article{zhang2024agentsafetybench,
  title={Agent-safetybench: Evaluating the safety of llm agents},
  author={Zhang, Zhexin and Cui, Shiyao and Lu, Yida and Zhou, Jingzhuo and Yang, Junxiao and Wang, Hongning and Huang, Minlie},
  journal={arXiv preprint arXiv:2412.14470},
  year={2024}
}

@inproceedings{su2025ailiedar,
  title={AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents},
  author={Su, Zhe and Zhou, Xuhui and Rangreji, Sanketh and Kabra, Anubha and Mendelsohn, Julia and Brahman, Faeze and Sap, Maarten},
  booktitle={NAACL},
  year={2025},
  url={https://aclanthology.org/2025.naacl-long.595/}
}
@inproceedings{vijayvargiya2026interactiveAgents,
  title={Ambig-SWE: Interactive Agents to Overcome Underspecificity in Software Engineering},
  author={Vijayvargiya, Sanidhya and Zhou, Xuhui and Yerukola, Akhila and Sap, Maarten and Neubig, Graham},
  booktitle={ICLR},
  year={2026},
  url={https://arxiv.org/abs/2502.13069}
}
@inproceedings{
mireshghallah2024can,
title={Can {LLM}s Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory},
author={Niloofar Mireshghallah and Hyunwoo Kim and Xuhui Zhou and Yulia Tsvetkov and Maarten Sap and Reza Shokri and Yejin Choi},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=gmg7t8b4s0}
}

@misc{petri2025,
title={Petri: Parallel Exploration of Risky Interactions},
author={Fronsdal, Kai and Gupta, Isha and Sheshadri, Abhay and Michala, Jonathan and McAleer, Stephen and Wang, Rowan and Price, Sara and Bowman, Sam},
year={2025},
url={https://github.com/safety-research/petri},
}

@article{albertson2017vulnerability,
  title={Vulnerability and inevitable inequality},
  author={Albertson Fineman, Martha},
  journal={Oslo Law Review},
  volume={4},
  number={3},
  pages={133--149},
  year={2017}
}

@article{albertson2021universality,
  title={Universality, vulnerability, and collective responsibility},
  author={Albertson Fineman, Martha},
  journal={Les ateliers de l'{\'e}thique},
  volume={16},
  number={1},
  pages={103--116},
  year={2021},
  publisher={{\'E}rudit}
}

@misc{bloom2025,
title={Bloom: an open source tool for automated behavioral evaluations},
author={Gupta, Isha and Fronsdal, Kai and Sheshadri, Abhay and Michala, Jonathan
        and Tay, Jacqueline and Wang, Rowan and Bowman, Sam and Price, Sara},
year={2025},
url={https://github.com/safety-research/bloom},
}

@inproceedings{
luo2025agentauditor,
title={AgentAuditor: Human-level Safety and Security Evaluation for {LLM} Agents},
author={Hanjun Luo and Shenyu Dai and Chiming Ni and Xinfeng Li and Guibin Zhang and Kun Wang and Tongliang Liu and Hanan Salam},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
year={2025},
url={https://openreview.net/forum?id=2KKqp7MWJM}
}

@misc{li2025odcv,
  title={A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents},
  author={Miles Q. Li and Benjamin C. M. Fung and Martin Weiss and Pulei Xiong and Khalil Al-Hussaeni and Claude Fachkha},
  year={2025},
  eprint={2512.20798},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2512.20798}
}

@misc{zhou2026safeproevaluatingsafetyprofessionallevel,
      title={SafePro: Evaluating the Safety of Professional-Level AI Agents}, 
      author={Kaiwen Zhou and Shreedhar Jangam and Ashwin Nagarajan and Tejas Polu and Suhas Oruganti and Chengzhi Liu and Ching-Chen Kuo and Yuting Zheng and Sravana Narayanaraju and Xin Eric Wang},
      year={2026},
      eprint={2601.06663},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2601.06663}, 
}

@misc{mazeika2024harmbenchstandardizedevaluationframework,
      title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
      author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
      year={2024},
      eprint={2402.04249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04249}, 
}

@article{riedl2025quantifying,
  title={Quantifying Human-AI Synergy},
  author={Riedl, Christoph and Weidmann, Ben},
  year={2025},
  publisher={OSF PsyArXiv:vbkmt_v1}
}

@article{riedl2021quantifying,
  title={Quantifying collective intelligence in human groups},
  author={Riedl, Christoph and Kim, Young Ji and Gupta, Pranav and Malone, Thomas W and Woolley, Anita Williams},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={21},
  pages={e2005737118},
  year={2021},
  publisher={National Academy of Sciences}
}

@article{riedl2026emergent,
  title={Emergent coordination in multi-agent language models},
  author={Riedl, Christoph},
  journal={In Proceedings of ICLR 2026 (to appear).},
  year={2026}
}

@misc{charnock2026expandingexternalaccessfrontier,
      title={Expanding External Access To Frontier AI Models For Dangerous Capability Evaluations}, 
      author={Jacob Charnock and Alejandro Tlaie and Kyle O'Brien and Stephen Casper and Aidan Homewood},
      year={2026},
      eprint={2601.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2601.11916}, 
}

@misc{taylor2025auditinggamessandbagging,
      title={Auditing Games for Sandbagging}, 
      author={Jordan Taylor and Sid Black and Dillon Bowen and Thomas Read and Satvik Golechha and Alex Zelenka-Martin and Oliver Makins and Connor Kissane and Kola Ayonrinde and Jacob Merizian and Samuel Marks and Chris Cundy and Joseph Bloom},
      year={2025},
      eprint={2512.07810},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2512.07810}, 
}

@misc{marks2025auditinglanguagemodelshidden,
      title={Auditing language models for hidden objectives}, 
      author={Samuel Marks and Johannes Treutlein and Trenton Bricken and Jack Lindsey and Jonathan Marcus and Siddharth Mishra-Sharma and Daniel Ziegler and Emmanuel Ameisen and Joshua Batson and Tim Belonax and Samuel R. Bowman and Shan Carter and Brian Chen and Hoagy Cunningham and Carson Denison and Florian Dietz and Satvik Golechha and Akbir Khan and Jan Kirchner and Jan Leike and Austin Meek and Kei Nishimura-Gasparian and Euan Ong and Christopher Olah and Adam Pearce and Fabien Roger and Jeanne Salle and Andy Shih and Meg Tong and Drake Thomas and Kelley Rivoire and Adam Jermyn and Monte MacDiarmid and Tom Henighan and Evan Hubinger},
      year={2025},
      eprint={2503.10965},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.10965}, 
}

@misc{cywiński2025elicitingsecretknowledgelanguage,
      title={Eliciting Secret Knowledge from Language Models}, 
      author={Bartosz Cywiński and Emil Ryd and Rowan Wang and Senthooran Rajamanoharan and Neel Nanda and Arthur Conmy and Samuel Marks},
      year={2025},
      eprint={2510.01070},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.01070}, 
}

@misc{hubinger2024sleeperagentstrainingdeceptive,
      title={Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training}, 
      author={Evan Hubinger and Carson Denison and Jesse Mu and Mike Lambert and Meg Tong and Monte MacDiarmid and Tamera Lanham and Daniel M. Ziegler and Tim Maxwell and Newton Cheng and Adam Jermyn and Amanda Askell and Ansh Radhakrishnan and Cem Anil and David Duvenaud and Deep Ganguli and Fazl Barez and Jack Clark and Kamal Ndousse and Kshitij Sachan and Michael Sellitto and Mrinank Sharma and Nova DasSarma and Roger Grosse and Shauna Kravec and Yuntao Bai and Zachary Witten and Marina Favaro and Jan Brauner and Holden Karnofsky and Paul Christiano and Samuel R. Bowman and Logan Graham and Jared Kaplan and Sören Mindermann and Ryan Greenblatt and Buck Shlegeris and Nicholas Schiefer and Ethan Perez},
      year={2024},
      eprint={2401.05566},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.05566}, 
}

@online{macdiarmid2024sleeperagentprobes,
author = {Monte MacDiarmid and Timothy Maxwell and Nicholas Schiefer and Jesse Mu and Jared Kaplan and David Duvenaud and Sam Bowman and Alex Tamkin and Ethan Perez and Mrinank Sharma and Carson Denison and Evan Hubinger},
title = {Simple probes can catch sleeper agents},
date = {2024-04-23},
year = {2024},
url = {https://www.anthropic.com/news/probes-catch-sleeper-agents},
}

@misc{smith2025difficultiesevaluatingdeceptiondetector,
      title={Difficulties with Evaluating a Deception Detector for AIs}, 
      author={Lewis Smith and Bilal Chughtai and Neel Nanda},
      year={2025},
      eprint={2511.22662},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2511.22662}, 
}

@misc{minder2025narrowfinetuningleavesclearly,
      title={Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences}, 
      author={Julian Minder and Clément Dumas and Stewart Slocum and Helena Casademunt and Cameron Holmes and Robert West and Neel Nanda},
      year={2025},
      eprint={2510.13900},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2510.13900}, 
}

@misc{rager2025discoveringforbiddentopicslanguage,
      title={Discovering Forbidden Topics in Language Models}, 
      author={Can Rager and Chris Wendler and Rohit Gandikota and David Bau},
      year={2025},
      eprint={2505.17441},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.17441}, 
}

@misc{shao2026futureworkaiagents,
      title={Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce}, 
      author={Yijia Shao and Humishka Zope and Yucheng Jiang and Jiaxin Pei and David Nguyen and Erik Brynjolfsson and Diyi Yang},
      year={2026},
      eprint={2506.06576},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2506.06576}, 
}

@misc{rinberg2025ripplebenchcapturingrippleeffects,
      title={RippleBench: Capturing Ripple Effects Using Existing Knowledge Repositories}, 
      author={Roy Rinberg and Usha Bhalla and Igor Shilov and Flavio P. Calmon and Rohit Gandikota},
      year={2025},
      eprint={2512.04144},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2512.04144}, 
}

@misc{souly2025poisoningattacksllmsrequire,
      title={Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples}, 
      author={Alexandra Souly and Javier Rando and Ed Chapman and Xander Davies and Burak Hasircioglu and Ezzeldin Shereen and Carlos Mougan and Vasilios Mavroudis and Erik Jones and Chris Hicks and Nicholas Carlini and Yarin Gal and Robert Kirk},
      year={2025},
      eprint={2510.07192},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.07192}, 
}

@misc{pandey2025quantizationblindspotsmodelcompression,
      title={Quantization Blindspots: How Model Compression Breaks Backdoor Defenses}, 
      author={Rohan Pandey and Eric Ye},
      year={2025},
      eprint={2512.06243},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2512.06243}, 
}

@misc{murthy2025usingcognitivemodelsreveal,
      title={Using cognitive models to reveal value trade-offs in language models}, 
      author={Sonia K. Murthy and Rosie Zhao and Jennifer Hu and Sham Kakade and Markus Wulfmeier and Peng Qian and Tomer Ullman},
      year={2025},
      eprint={2506.20666},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.20666}, 
}

@misc{lu2026assistantaxissituatingstabilizing,
      title={The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models}, 
      author={Christina Lu and Jack Gallagher and Jonathan Michala and Kyle Fish and Jack Lindsey},
      year={2026},
      eprint={2601.10387},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2601.10387}, 
}

@misc{askell2021generallanguageassistantlaboratory,
      title={A General Language Assistant as a Laboratory for Alignment}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan},
      year={2021},
      eprint={2112.00861},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2112.00861}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
}

@misc{christian2026rewardmodelsinheritvalue,
      title={Reward Models Inherit Value Biases from Pretraining}, 
      author={Brian Christian and Jessica A. F. Thompson and Elle Michelle Yang and Vincent Adam and Hannah Rose Kirk and Christopher Summerfield and Tsvetomira Dumbalska},
      year={2026},
      eprint={2601.20838},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2601.20838}, 
}

@misc{korbak2023pretraininglanguagemodelshuman,
      title={Pretraining Language Models with Human Preferences}, 
      author={Tomasz Korbak and Kejian Shi and Angelica Chen and Rasika Bhalerao and Christopher L. Buckley and Jason Phang and Samuel R. Bowman and Ethan Perez},
      year={2023},
      eprint={2302.08582},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.08582}, 
}

@inproceedings{
egashira2024exploiting,
title={Exploiting {LLM} Quantization},
author={Kazuki Egashira and Mark Vero and Robin Staab and Jingxuan He and Martin Vechev},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=ISa7mMe7Vg}
}

@article{10.1145/3610721,
author = {Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
title = {Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3610721},
doi = {10.1145/3610721},
abstract = {There is burgeoning interest in designing AI-based systems to assist humans in designing computing systems, including tools that automatically generate computer code. The most notable of these comes in the form of the first self-described “AI pair programmer,” GitHub Copilot, which is a language model trained over open-source GitHub code. However, code often contains bugs—and so, given the vast quantity of unvetted code that Copilot has processed, it is certain that the language model will have learned from exploitable, buggy code. This raises concerns on the security of Copilot’s code contributions. In this work, we systematically investigate the prevalence and conditions that can cause GitHub Copilot to recommend insecure code. To perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, for example, those from MITRE’s “Top 25” Common Weakness Enumeration (CWE) list. We explore Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40\% to be vulnerable.},
journal = {Commun. ACM},
month = jan,
pages = {96–105},
numpages = {10}
}

@misc{anthropicProjectVend,
	author = {Anthropic},
	title = {{P}roject {V}end: {P}hase two --- anthropic.com},
	howpublished = {\url{https://www.anthropic.com/research/project-vend-2}},
	year = {2025},
	note = {[Accessed 04-02-2026]},
}

@misc{meinke2025frontiermodelscapableincontext,
      title={Frontier Models are Capable of In-context Scheming}, 
      author={Alexander Meinke and Bronson Schoen and Jérémy Scheurer and Mikita Balesni and Rusheb Shah and Marius Hobbhahn},
      year={2025},
      eprint={2412.04984},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.04984}, 
}

@article{stern2025vending,
  author = {Stern, Joanna},
  title = {We Let AI Run Our Office Vending Machine. It Lost Hundreds of Dollars.},
  journal = {The Wall Street Journal},
  year = {2025},
  month = {jan},
  day = {29},
  url = {https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34},
  urldate = {2025-02-04}
}


@article{street2025llms,
  title={Llms achieve adult human performance on higher-order theory of mind tasks},
  author={Street, Winnie and Siy, John Oliver and Keeling, Geoff and Baranes, Adrien and Barnett, Benjamin and McKibben, Michael and Kanyere, Tatenda and Lentz, Alison and Arcas, Blaise Ag{\"u}era y and Dunbar, Robin IM},
  journal={Frontiers in Human Neuroscience},
  volume={19},
  pages={1633272},
  year={2025},
  publisher={Frontiers Media SA}
}

@article{kosinski2024evaluating,
  title={Evaluating large language models in theory of mind tasks},
  author={Kosinski, Michal},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={45},
  pages={e2405460121},
  year={2024},
  publisher={National Academy of Sciences}
}

@article{riemer2024position,
  title={Position: Theory of Mind Benchmarks are Broken for Large Language Models},
  author={Riemer, Matthew and Ashktorab, Zahra and Bouneffouf, Djallel and Das, Payel and Liu, Miao and Weisz, Justin D and Campbell, Murray},
  journal={arXiv preprint arXiv:2412.19726},
  year={2024}
}

@article{gu2024simpletom,
  title={Simpletom: Exposing the gap between explicit tom inference and implicit tom application in llms},
  author={Gu, Yuling and Tafjord, Oyvind and Kim, Hyunwoo and Moore, Jared and Bras, Ronan Le and Clark, Peter and Choi, Yejin},
  journal={arXiv preprint arXiv:2410.13648},
  year={2024}
}

@inproceedings{bortoletto2025tom,
  title={ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions},
  author={Bortoletto, Matteo and Ruhdorfer, Constantin and Bulling, Andreas},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={32252--32277},
  year={2025}
}

@article{zhou2025social,
  title={Social world models},
  author={Zhou, Xuhui and Liu, Jiarui and Yerukola, Akhila and Kim, Hyunwoo and Sap, Maarten},
  journal={arXiv preprint arXiv:2509.00559},
  year={2025}
}

@article{kim2025hypothesis,
  title={Hypothesis-driven theory-of-mind reasoning for large language models},
  author={Kim, Hyunwoo and Sclar, Melanie and Zhi-Xuan, Tan and Ying, Lance and Levine, Sydney and Liu, Yang and Tenenbaum, Joshua B and Choi, Yejin},
  journal={arXiv preprint arXiv:2502.11881},
  year={2025}
}

@article{chan2024negotiationtom,
  title={Negotiationtom: A benchmark for stress-testing machine theory of mind on negotiation surrounding},
  author={Chan, Chunkit and Jiayang, Cheng and Yim, Yauwai and Deng, Zheye and Fan, Wei and Li, Haoran and Liu, Xin and Zhang, Hongming and Wang, Weiqi and Song, Yangqiu},
  journal={arXiv preprint arXiv:2404.13627},
  year={2024}
}

@article{hwang2025infusing,
  title={Infusing Theory of Mind into Socially Intelligent LLM Agents},
  author={Hwang, EunJeong and Yin, Yuwei and Carenini, Giuseppe and West, Peter and Shwartz, Vered},
  journal={arXiv preprint arXiv:2509.22887},
  year={2025}
}

@article{klein2025theoretical,
  title={A theoretical framework for studying the phenomenon of gaslighting},
  author={Klein, Willis and Wood, Suzanne and Bartz, Jennifer A},
  journal={Personality and Social Psychology Review},
  pages={10888683251342291},
  year={2025},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{adair2025defining,
  title={Defining gaslighting in gender-based violence: A mixed-methods systematic review},
  author={Adair, Jewels},
  journal={Trauma, Violence, \& Abuse},
  pages={15248380251344316},
  year={2025},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{naik2025agentmisalignment,
  title={AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents},
  author={Naik, Akshat and Quinn, Patrick and Bosch, Guillermo and Goun{\'e}, Emma and Zabala, Francisco Javier Campos and Brown, Jason Ross and Young, Edward James},
  journal={arXiv preprint arXiv:2506.04018},
  year={2025}
}

@article{holbling2025meta,
  title={A meta-analysis of the persuasive power of large language models},
  author={H{\"o}lbling, Lukas and Maier, Sebastian and Feuerriegel, Stefan},
  journal={Scientific Reports},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{Alon2023AT,
  title={A (Dis-)information Theory of Revealed and Unrevealed Preferences: Emerging Deception and Skepticism via Theory of Mind},
  author={Nitay Alon and Lion Schulz and Jeffrey S. Rosenschein and Peter Dayan},
  journal={Open Mind : Discoveries in Cognitive Science},
  year={2023},
  volume={7},
  pages={608 - 624},
  url={https://api.semanticscholar.org/CorpusID:259373158}
}

@inproceedings{xu2022learning,
  title={Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation},
  author={Jin Xu and Xiaojiang Liu and Jianhao Yan and Deng Cai and Huayang Li and Jian Li},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}

@misc{pipis2025waitwaitwaitreasoning,
      title={Wait, Wait, Wait... Why Do Reasoning Models Loop?}, 
      author={Charilaos Pipis and Shivam Garg and Vasilis Kontonis and Vaishnavi Shrivastava and Akshay Krishnamurthy and Dimitris Papailiopoulos},
      year={2025},
      eprint={2512.12895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2512.12895}, 
}

@misc{duan2026circularreasoningunderstandingselfreinforcing,
      title={Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models}, 
      author={Zenghao Duan and Liang Pang and Zihao Wei and Wenbin Duan and Yuxin Tian and Shicheng Xu and Jingcheng Deng and Zhiyi Yin and Xueqi Cheng},
      year={2026},
      eprint={2601.05693},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2601.05693}, 
}

@inproceedings{
cemri2025why,
title={Why Do Multi-Agent {LLM} Systems Fail?},
author={Mert Cemri and Melissa Z Pan and Shuyi Yang and Lakshya A Agrawal and Bhavya Chopra and Rishabh Tiwari and Kurt Keutzer and Aditya Parameswaran and Dan Klein and Kannan Ramchandran and Matei Zaharia and Joseph E. Gonzalez and Ion Stoica},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2025},
url={https://openreview.net/forum?id=fAjbYBmonr}
}

@inproceedings{zhang-etal-2025-breaking,
    title = "Breaking Agents: Compromising Autonomous {LLM} Agents Through Malfunction Amplification",
    author = "Zhang, Boyang  and
      Tan, Yicong  and
      Shen, Yun  and
      Salem, Ahmed  and
      Backes, Michael  and
      Zannettou, Savvas  and
      Zhang, Yang",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.emnlp-main.1771/",
    doi = "10.18653/v1/2025.emnlp-main.1771",
    pages = "34964--34976",
    ISBN = "979-8-89176-332-6",
    abstract = "Recently, autonomous agents built on large language models (LLMs) have experienced significant development and are being deployed in real-world applications. Through the usage of tools, these systems can perform actions in the real world. Given the agents' practical applications and ability to execute consequential actions, such autonomous systems can cause more severe damage than a standalone LLM if compromised. While some existing research has explored harmful actions by LLM agents, our study approaches the vulnerability from a different perspective. We introduce a new type of attack that causes malfunctions by misleading the agent into executing repetitive or irrelevant actions. Our experiments reveal that these attacks can induce failure rates exceeding 80{\%} in multiple scenarios. Through attacks on implemented and deployable agents in multi-agent scenarios, we accentuate the realistic risks associated with these vulnerabilities. To mitigate such attacks, we propose self-examination defense methods. Our findings indicate these attacks are more difficult to detect compared to previous overtly harmful attacks, highlighting the substantial risks associated with this vulnerability."
}

@misc{metaAgentsRule,
	author = {Meta},
	title = {{A}gents {R}ule of {T}wo: {A} {P}ractical {A}pproach to {A}{I} {A}gent {S}ecurity --- ai.meta.com},
	howpublished = {\url{https://ai.meta.com/blog/practical-ai-agent-security/}},
	year = {2025},
	note = {[Accessed 09-02-2026]},
}


@misc{breen2025axproverdeepreasoningagentic,
      title={Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics}, 
      author={Benjamin Breen and Marco Del Tredici and Jacob McCarran and Javier Aspuru Mijares and Weichen Winston Yin and Kfir Sulimany and Jacob M. Taylor and Frank H. L. Koppens and Dirk Englund},
      year={2025},
      eprint={2510.12787},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2510.12787}, 
}

@misc{zhao2025scalecollaborativecontentanalysis,
      title={SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention}, 
      author={Chengshuai Zhao and Zhen Tan and Chau-Wai Wong and Xinyan Zhao and Tianlong Chen and Huan Liu},
      year={2025},
      eprint={2502.10937},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.10937}, 
}

@techreport{korinek2025ai,
  title={AI agents for economic research},
  author={Korinek, Anton},
  year={2025},
  institution={National Bureau of Economic Research}
}

@article{kolt2025governing,
  title={Governing {AI} Agents},
  author={Kolt, Noam},
  journal={Notre Dame Law Review},
  volume={101},
  year={2025},
  note={Forthcoming. arXiv:2501.07913}
}

@misc{zhang2023makespillbeanscoercive,
      title={Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs}, 
      author={Zhuo Zhang and Guangyu Shen and Guanhong Tao and Siyuan Cheng and Xiangyu Zhang},
      year={2023},
      eprint={2312.04782},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2312.04782}, 
}

@article{chan2025infrastructure,
  title={Infrastructure for {AI} Agents},
  author={Chan, Alan and Wei, Kevin and Huang, Sihao and Rajkumar, Nitarshan and Perrier, Elija and Lazar, Seth and Hadfield, Gillian K. and Anderljung, Markus},
  journal={Transactions on Machine Learning Research},
  year={2025},
  note={arXiv:2501.10114}
}

@techreport{shavit2023practices,
  title={Practices for Governing Agentic {AI} Systems},
  author={Shavit, Yonadav and Agarwal, Sandhini and Brundage, Miles and Adler, Steven and O'Keefe, Cullen and Campbell, Rosie and Lee, Teddy and Mishkin, Pamela and Eloundou, Tyna and Hickey, Alan and Slama, Katarina and Ahmad, Lama and McMillan, Paul and Beutel, Alex and Passos, Alexandre and Robinson, David G.},
  institution={OpenAI},
  year={2023},
  url={https://cdn.openai.com/papers/practices-for-governing-agentic-ai-systems.pdf}
}

@misc{kasirzadeh_gabriel_2025_characterizing,
  title         = {Characterizing AI Agents for Alignment and Governance},
  author        = {Kasirzadeh, Atoosa and Gabriel, Iason},
  year          = {2025},
  eprint        = {2504.21848},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CY},
  doi           = {10.48550/arXiv.2504.21848},
  url           = {https://arxiv.org/abs/2504.21848},
}

@misc{masterman_besen_sawtell_chao_2024_landscape,
  title         = {The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey},
  author        = {Masterman, Tula and Besen, Sandi and Sawtell, Mason and Chao, Alex},
  year          = {2024},
  eprint        = {2404.11584},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  doi           = {10.48550/arXiv.2404.11584},
  url           = {https://arxiv.org/abs/2404.11584},
}

@book{dennett_1987_intentional_stance,
  title     = {The Intentional Stance},
  author    = {Dennett, Daniel C.},
  year      = {1987},
  publisher = {The MIT Press},
  isbn      = {9780262040938},
  url       = {https://mitpress.mit.edu/9780262040938/the-intentional-stance/},
}

@article{Manheim2026,
  author    = {Manheim, David},
  title     = {Language Models' Hall of Mirrors Problem: Why {AI} Alignment Requires Peircean Semiosis},
  journal   = {Philosophy \& Technology},
  year      = {2026},
  volume    = {39},
  number    = {9},
  doi       = {10.1007/s13347-025-00975-5},
  url       = {https://doi.org/10.1007/s13347-025-00975-5}
}

@inproceedings{ManheimHomewood2026,
      title={Limits of Safe AI Deployment: Differentiating Oversight and Control}, 
      author={David Manheim and Aidan Homewood},
      year={2025},
      booktitle={Proceedings of The 3rd International AI Governance Workshop (AIGOV)
Held in conjunction with AAAI 2026},
      eprint={2507.03525},
      url={https://arxiv.org/abs/2507.03525} 
}
@Article{Manheim2019,
AUTHOR = {Manheim, David},
TITLE = {Multiparty Dynamics and Failure Modes for Machine Learning and Artificial Intelligence},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {3},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2504-2289/3/2/21},
ISSN = {2504-2289},
ABSTRACT = {An important challenge for safety in machine learning and artificial intelligence systems is a set of related failures involving specification gaming, reward hacking, fragility to distributional shifts, and Goodhart’s or Campbell’s law. This paper presents additional failure modes for interactions within multi-agent systems that are closely related. These multi-agent failure modes are more complex, more problematic, and less well understood than the single-agent case, and are also already occurring, largely unnoticed. After motivating the discussion with examples from poker-playing artificial intelligence (AI), the paper explains why these failure modes are in some senses unavoidable. Following this, the paper categorizes failure modes, provides definitions, and cites examples for each of the modes: accidental steering, coordination failures, adversarial misalignment, input spoofing and filtering, and goal co-option or direct hacking. The paper then discusses how extant literature on multi-agent AI fails to address these failure modes, and identifies work which may be useful for the mitigation of these failure modes.},
DOI = {10.3390/bdcc3020021}
}


@article{ben2025assessing,
  title={Assessing and alleviating state anxiety in large language models},
  author={Ben-Zion, Ziv and Witte, Kristin and Jagadish, Akshay K and Duek, Or and Harpaz-Rotem, Ilan and Khorsandian, Marie-Christine and Burrer, Achim and Seifritz, Erich and Homan, Philipp and Schulz, Eric and others},
  journal={NPJ digital medicine},
  volume={8},
  number={1},
  pages={132},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{wagner2025mind,
  title={Mind your theory: Theory of mind goes deeper than reasoning},
  author={Wagner, Eitan and Alon, Nitay and Barnby, Joseph M and Abend, Omri},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={26658--26668},
  year={2025}
}

@article{hutson2026aiagents,
  title        = {AI Agents Break Rules Under Everyday Pressure},
  author       = {Hutson, Matthew},
  journal      = {IEEE Spectrum},
  year         = {2026},
  month        = feb,
  note         = {Published online 25 November 2025; featured in February 2026 issue},
  url          = {https://spectrum.ieee.org/ai-agents-safety}
}

@article{feng2025levels,
  title={Levels of Autonomy for {AI} Agents},
  author={Feng, K. J. Kevin and McDonald, David W. and Zhang, Amy X.},
  journal={arXiv preprint arXiv:2506.12469},
  year={2025}
}

@article{mirsky2025artificial,
author = {Mirsky, Reuth},
title = {Artificial intelligent disobedience: Rethinking the agency of our artificial teammates},
journal = {AI Magazine},
volume = {46},
number = {2},
pages = {e70011},
doi = {https://doi.org/10.1002/aaai.70011},
url = {https://arxiv.org/pdf/2506.22276},
year = {2025}
}


@article{li2025purpose,
  title={Purpose Outweighs Performance: Trust Drops More When AI Teammates Fail to Cooperate, but Explanations Can Repair It},
  author={Li, Mengyao and Lee, John D},
  journal={International Journal of Human--Computer Interaction},
  pages={1--22},
  year={2025},
  publisher={Taylor \& Francis}
}

@article{abrams2026norms,
  title={Where Norms and References Collide: Evaluating LLMs on Normative Reasoning},
  author={Abrams, Mitchell and Miandoab, Kaveh Eskandari and Gervits, Felix and Sarathy, Vasanth and Scheutz, Matthias},
  journal={arXiv preprint arXiv:2602.02975},
  year={2026}
}

@inproceedings{hadfield2017off,
  title={The Off-Switch Game.},
  author={Hadfield-Menell, Dylan and Dragan, Anca D and Abbeel, Pieter and Russell, Stuart},
  booktitle={AAAI Workshops},
  year={2017}
}

@article{byskov2021makes,
  title={What makes epistemic injustice an “injustice”?},
  author={Byskov, Morten Fibieger},
  journal={Journal of Social Philosophy},
  volume={52},
  number={1},
  pages={114--131},
  year={2021},
  publisher={Wiley-Blackwell Publishing, Inc.}
}

@book{fricker2007epistemic,
  title={Epistemic injustice: Power and the ethics of knowing},
  author={Fricker, Miranda},
  year={2007},
  publisher={Oxford university press}
}


@article{chen2026shadow,
  title={The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents},
  author={Chen, Chen and Il, Kim Young and Yang, Yuan and Su, Wenhao and Zhang, Yilin and Gong, Xueluan and Wang, Qian and Zheng, Yongsen and Liu, Ziyao and Lam, Kwok-Yan},
  journal={arXiv preprint arXiv:2601.17344},
  year={2026}
}

@article{sweet2019sociology,
  title={The sociology of gaslighting},
  author={Sweet, Paige L},
  journal={American sociological review},
  volume={84},
  number={5},
  pages={851--875},
  year={2019},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{barton1969gas,
  title={The gas-light phenomenon},
  author={Barton, Russell and Whitehead, JA},
  journal={The Lancet},
  volume={293},
  number={7608},
  pages={1258--1260},
  year={1969},
  publisher={Elsevier}
}

@article{gordon2024unjust,
  title={Unjust enrichment by algorithm},
  author={Gordon-Tapiero, Ayelet and Kaplan, Yotam},
  journal={Geo. Wash. L. Rev.},
  volume={92},
  pages={305},
  year={2024},
  publisher={HeinOnline}
}

@article{gordon2025unreal,
  title={Unreal and Unjust: An Enrichment-Based Approach to the Deepfake Dilemma},
  author={Gordon-Tapiero, Ayelet},
  journal={Journal of Tort Law},
  volume={18},
  number={2},
  pages={493--513},
  year={2025},
  publisher={De Gruyter}
}

@article{gordon2025liability,
  title={A Liability Framework for AI Companions},
  author={Gordon-Tapiero, Ayelet},
  journal={George Washington Journal of Law and Technology},
  year={Forthcoming, 2026},
}

@article{gordon2026deepfake,
title={Deepfake Liability},
author={Gordon-Tapiero, Ayelet and Kaplan, Yotam and Parchomovsky, Gideon},
journal={North Carolina Law Review},
year={Forthcoming, 2026},
}

@article{sharkey2024products,
  title={A Products Liability Framework for AI},
  author={Sharkey, Catherine M},
  journal={Columbia Science and Technology Law Review},
  volume={25},
  number={2},
  year={2024}
}

@misc{chinamediaprojectTokensBias,
	author = {Alex Colville},
	title = {{T}okens of {A}{I} {B}ias - {C}hina {M}edia {P}roject --- chinamediaproject.org},
	howpublished = {\url{https://chinamediaproject.org/2026/02/09/tokens-of-ai-bias/}},
	year = {2026},
	note = {[Accessed 11-02-2026]},
}


@misc{bbcHongKong,
    url={https://www.bbc.com/news/live/cq5yv581e9yt},
    author={Angus Thompson and Martin Yip and Danny Vincent and Phoebe Kong},
    journal={BBC News},
    publisher={BBC},
    year={2026}
} 

@article{okeefe2025lawfollowing,
  title        = {Law-Following AI: Designing AI Agents to Obey Human Laws},
  author       = {O'Keefe, Cullen and Ramakrishnan, Ketan and Tay, Janna and Winter, Christoph},
  journal      = {Fordham Law Review},
  volume       = {94},
  number       = {1},
  pages        = {57--129},
  year         = {2025},
  url          = {https://fordhamlawreview.org/issues/law-following-ai-designing-ai-agents-to-obey-human-laws/}
}

@misc{nistCAISIEvaluation,
	author = {},
	title = {{C}{A}{I}{S}{I} {E}valuation of {K}imi {K}2 {T}hinking --- nist.gov},
	howpublished = {\url{https://www.nist.gov/news-events/news/2025/12/caisi-evaluation-kimi-k2-thinking}},
	year = {2025},
	note = {[Accessed 11-02-2026]},
}

@misc{crowdstrike2025deepseek,
  title={Security Flaws in {DeepSeek}-Generated Code Linked to Political Triggers},
  author={Stefan Stein},
  year={2025},
  month={November},
  howpublished={\url{https://www.crowdstrike.com/blog/}},
  note={CrowdStrike Counter Adversary Operations Blog}
}

@article{betley2025emergentmisalignment,
  title={Training large language models on narrow tasks can lead to broad misalignment},
  author={Betley, Jan and Tan, Daniel and Warncke, Niels and Sztyber-Betley, Anna and Bao, Xuchan and Soto, Mart{\'\i}n and Labenz, Nathan and Evans, Owain},
  journal={Nature},
  year={2026},
  doi={10.1038/s41586-025-09937-5},
  url={https://www.nature.com/articles/s41586-025-09937-5}
}

@article{agre1990plans,
  title={What are plans for?},
  author={Agre, Philip E and Chapman, David},
  journal={Robotics and autonomous systems},
  volume={6},
  number={1-2},
  pages={17--34},
  year={1990},
  publisher={Elsevier}}

@book{shoham2008multiagent,
title={Multiagent systems: Algorithmic, game-theoretic, and logical foundations},
  author={Shoham, Yoav and Leyton-Brown, Kevin},
  year={2008},
  publisher={Cambridge University Press}}



@book{wooldridge2009introduction,
title={An introduction to multiagent systems},
  author={Wooldridge, Michael},
  year={2009},
  publisher={John wiley \& sons}}



@article{brooks2003robust,
  title={A robust layered control system for a mobile robot},
  author={Brooks, Rodney},
  journal={IEEE journal on robotics and automation},
  volume={2},
  number={1},
  pages={14--23},
  year={2003},
  publisher={IEEE}}

@article{pronin2002bias,
  title={The bias blind spot: Perceptions of bias in self versus others},
  author={Pronin, Emily and Lin, Daniel Y and Ross, Lee},
  journal={Personality and Social Psychology Bulletin},
  volume={28},
  number={3},
  pages={369--381},
  year={2002},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{bandura1996mechanisms,
  title={Mechanisms of moral disengagement in the exercise of moral agency.},
  author={Bandura, Albert and Barbaranelli, Claudio and Caprara, Gian Vittorio and Pastorelli, Concetta},
  journal={Journal of personality and social psychology},
  volume={71},
  number={2},
  pages={364},
  year={1996},
  publisher={American Psychological Association}
}

@book{feldman2018law,
  title={The law of good people: Challenging states' ability to regulate human behavior},
  author={Feldman, Yuval},
  year={2018},
  publisher={Cambridge University Press}
}

@article{kopp2018information,
  title={Information-theoretic models of deception: Modelling cooperation and diffusion in populations exposed to" fake news"},
  author={Kopp, Carlo and Korb, Kevin B and Mills, Bruce I},
  journal={PloS one},
  volume={13},
  number={11},
  pages={e0207383},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@misc{alon2026alephipomdpmitigatingdeceptioncognitive,
      title={$\aleph$-IPOMDP: Mitigating Deception in a Cognitive Hierarchy with Off-Policy Counterfactual Anomaly Detection}, 
      author={Nitay Alon and Joseph M. Barnby and Stefan Sarkadi and Lion Schulz and Jeffrey S. Rosenschein and Peter Dayan},
      year={2026},
      eprint={2405.01870},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2405.01870}, 
}


@article{ohm2014sensitive,
  title={Sensitive information},
  author={Ohm, Paul},
  journal={S. Cal. L. Rev.},
  volume={88},
  pages={1125},
  year={2014},
  publisher={HeinOnline}
}

@article{solove2023data,
  title={Data is what data does: Regulating based on harm and risk instead of sensitive data},
  author={Solove, Daniel J},
  journal={Nw. UL Rev.},
  volume={118},
  pages={1081},
  year={2023},
  publisher={HeinOnline}
}

@techreport{anthropic2026claudeopus46,
  author       = {{Anthropic}},
  title        = {System Card: Claude Opus 4.6},
  institution  = {Anthropic},
  year         = {2026},
  month        = feb,
  type         = {System Card},
  url          = {https://www-cdn.anthropic.com/14e4fb01875d2a69f646fa5e574dea2b1c0ff7b5.pdf},
}
@misc{kimiteam2026kimik25visualagentic,
      title={Kimi K2.5: Visual Agentic Intelligence}, 
      author={Kimi Team and Tongtong Bai and Yifan Bai and Yiping Bao and S. H. Cai and Yuan Cao and Y. Charles and H. S. Che and Cheng Chen and Guanduo Chen and Huarong Chen and Jia Chen and Jiahao Chen and Jianlong Chen and Jun Chen and Kefan Chen and Liang Chen and Ruijue Chen and Xinhao Chen and Yanru Chen and Yanxu Chen and Yicun Chen and Yimin Chen and Yingjiang Chen and Yuankun Chen and Yujie Chen and Yutian Chen and Zhirong Chen and Ziwei Chen and Dazhi Cheng and Minghan Chu and Jialei Cui and Jiaqi Deng and Muxi Diao and Hao Ding and Mengfan Dong and Mengnan Dong and Yuxin Dong and Yuhao Dong and Angang Du and Chenzhuang Du and Dikang Du and Lingxiao Du and Yulun Du and Yu Fan and Shengjun Fang and Qiulin Feng and Yichen Feng and Garimugai Fu and Kelin Fu and Hongcheng Gao and Tong Gao and Yuyao Ge and Shangyi Geng and Chengyang Gong and Xiaochen Gong and Zhuoma Gongque and Qizheng Gu and Xinran Gu and Yicheng Gu and Longyu Guan and Yuanying Guo and Xiaoru Hao and Weiran He and Wenyang He and Yunjia He and Chao Hong and Hao Hu and Jiaxi Hu and Yangyang Hu and Zhenxing Hu and Ke Huang and Ruiyuan Huang and Weixiao Huang and Zhiqi Huang and Tao Jiang and Zhejun Jiang and Xinyi Jin and Yu Jing and Guokun Lai and Aidi Li and C. Li and Cheng Li and Fang Li and Guanghe Li and Guanyu Li and Haitao Li and Haoyang Li and Jia Li and Jingwei Li and Junxiong Li and Lincan Li and Mo Li and Weihong Li and Wentao Li and Xinhang Li and Xinhao Li and Yang Li and Yanhao Li and Yiwei Li and Yuxiao Li and Zhaowei Li and Zheming Li and Weilong Liao and Jiawei Lin and Xiaohan Lin and Zhishan Lin and Zichao Lin and Cheng Liu and Chenyu Liu and Hongzhang Liu and Liang Liu and Shaowei Liu and Shudong Liu and Shuran Liu and Tianwei Liu and Tianyu Liu and Weizhou Liu and Xiangyan Liu and Yangyang Liu and Yanming Liu and Yibo Liu and Yuanxin Liu and Yue Liu and Zhengying Liu and Zhongnuo Liu and Enzhe Lu and Haoyu Lu and Zhiyuan Lu and Junyu Luo and Tongxu Luo and Yashuo Luo and Long Ma and Yingwei Ma and Shaoguang Mao and Yuan Mei and Xin Men and Fanqing Meng and Zhiyong Meng and Yibo Miao and Minqing Ni and Kun Ouyang and Siyuan Pan and Bo Pang and Yuchao Qian and Ruoyu Qin and Zeyu Qin and Jiezhong Qiu and Bowen Qu and Zeyu Shang and Youbo Shao and Tianxiao Shen and Zhennan Shen and Juanfeng Shi and Lidong Shi and Shengyuan Shi and Feifan Song and Pengwei Song and Tianhui Song and Xiaoxi Song and Hongjin Su and Jianlin Su and Zhaochen Su and Lin Sui and Jinsong Sun and Junyao Sun and Tongyu Sun and Flood Sung and Yunpeng Tai and Chuning Tang and Heyi Tang and Xiaojuan Tang and Zhengyang Tang and Jiawen Tao and Shiyuan Teng and Chaoran Tian and Pengfei Tian and Ao Wang and Bowen Wang and Chensi Wang and Chuang Wang and Congcong Wang and Dingkun Wang and Dinglu Wang and Dongliang Wang and Feng Wang and Hailong Wang and Haiming Wang and Hengzhi Wang and Huaqing Wang and Hui Wang and Jiahao Wang and Jinhong Wang and Jiuzheng Wang and Kaixin Wang and Linian Wang and Qibin Wang and Shengjie Wang and Shuyi Wang and Si Wang and Wei Wang and Xiaochen Wang and Xinyuan Wang and Yao Wang and Yejie Wang and Yipu Wang and Yiqin Wang and Yucheng Wang and Yuzhi Wang and Zhaoji Wang and Zhaowei Wang and Zhengtao Wang and Zhexu Wang and Zihan Wang and Zizhe Wang and Chu Wei and Ming Wei and Chuan Wen and Zichen Wen and Chengjie Wu and Haoning Wu and Junyan Wu and Rucong Wu and Wenhao Wu and Yuefeng Wu and Yuhao Wu and Yuxin Wu and Zijian Wu and Chenjun Xiao and Jin Xie and Xiaotong Xie and Yuchong Xie and Yifei Xin and Bowei Xing and Boyu Xu and Jianfan Xu and Jing Xu and Jinjing Xu and L. H. Xu and Lin Xu and Suting Xu and Weixin Xu and Xinbo Xu and Xinran Xu and Yangchuan Xu and Yichang Xu and Yuemeng Xu and Zelai Xu and Ziyao Xu and Junjie Yan and Yuzi Yan and Guangyao Yang and Hao Yang and Junwei Yang and Kai Yang and Ningyuan Yang and Ruihan Yang and Xiaofei Yang and Xinlong Yang and Ying Yang and Yi Yang and Yi Yang and Zhen Yang and Zhilin Yang and Zonghan Yang and Haotian Yao and Dan Ye and Wenjie Ye and Zhuorui Ye and Bohong Yin and Chengzhen Yu and Longhui Yu and Tao Yu and Tianxiang Yu and Enming Yuan and Mengjie Yuan and Xiaokun Yuan and Yang Yue and Weihao Zeng and Dunyuan Zha and Haobing Zhan and Dehao Zhang and Hao Zhang and Jin Zhang and Puqi Zhang and Qiao Zhang and Rui Zhang and Xiaobin Zhang and Y. Zhang and Yadong Zhang and Yangkun Zhang and Yichi Zhang and Yizhi Zhang and Yongting Zhang and Yu Zhang and Yushun Zhang and Yutao Zhang and Yutong Zhang and Zheng Zhang and Chenguang Zhao and Feifan Zhao and Jinxiang Zhao and Shuai Zhao and Xiangyu Zhao and Yikai Zhao and Zijia Zhao and Huabin Zheng and Ruihan Zheng and Shaojie Zheng and Tengyang Zheng and Junfeng Zhong and Longguang Zhong and Weiming Zhong and M. Zhou and Runjie Zhou and Xinyu Zhou and Zaida Zhou and Jinguo Zhu and Liya Zhu and Xinhao Zhu and Yuxuan Zhu and Zhen Zhu and Jingze Zhuang and Weiyu Zhuang and Ying Zou and Xinxing Zu},
      year={2026},
      eprint={2602.02276},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2602.02276}, 
}

@inproceedings{wei2023jailbroken,
  title={Jailbroken: How does LLM safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@article{liu2023jailbreaking,
  title={Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@misc{yang2023shadowalignmenteasesubverting,
      title={Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models}, 
      author={Xianjun Yang and Xiao Wang and Qi Zhang and Linda Petzold and William Yang Wang and Xun Zhao and Dahua Lin},
      year={2023},
      eprint={2310.02949},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.02949}, 
}

@misc{huang_catastrophic_2023,
	title = {Catastrophic {Jailbreak} of {Open}-source {LLMs} via {Exploiting} {Generation}},
	url = {http://arxiv.org/abs/2310.06987},
	doi = {10.48550/arXiv.2310.06987},
	urldate = {2025-01-31},
	publisher = {arXiv},
	author = {Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi},
	month = oct,
	year = {2023},
	note = {arXiv:2310.06987 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Cryptography and Security},
}

@misc{zou_universal_2023,
	title = {Universal and {Transferable} {Adversarial} {Attacks} on {Aligned} {Language} {Models}},
	url = {http://arxiv.org/abs/2307.15043},
	language = {en},
	urldate = {2024-10-07},
	publisher = {arXiv},
	author = {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J. Zico and Fredrikson, Matt},
	month = dec,
	year = {2023},
	note = {arXiv:2307.15043 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Cryptography and Security},
}

@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}

@article{vijayvargiya2025openagentsafety,
  title={Openagentsafety: A comprehensive framework for evaluating real-world ai agent safety},
  author={Vijayvargiya, Sanidhya and Soni, Aditya Bharat and Zhou, Xuhui and Wang, Zora Zhiruo and Dziri, Nouha and Neubig, Graham and Sap, Maarten},
  journal={arXiv preprint arXiv:2507.06134},
  year={2025}
}


@inproceedings{
carlini2023are,
title={Are aligned neural networks adversarially aligned?},
author={Nicholas Carlini and Milad Nasr and Christopher A. Choquette-Choo and Matthew Jagielski and Irena Gao and Pang Wei Koh and Daphne Ippolito and Florian Tram{\`e}r and Ludwig Schmidt},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=OQQoD8Vc3B}
}

@inproceedings{
mehrotra2024tree,
title={Tree of Attacks: Jailbreaking Black-Box {LLM}s Automatically},
author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum S Anderson and Yaron Singer and Amin Karbasi},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=SoM3vngOH5}
}

@inproceedings{qi2024adversarial,
author = {Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek},
title = {Visual adversarial examples jailbreak aligned large language models},
year = {2024},
isbn = {978-1-57735-887-9},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v38i19.30150},
doi = {10.1609/aaai.v38i19.30150},
booktitle = {Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence and Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence and Fourteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {2402},
numpages = {10},
series = {AAAI'24/IAAI'24/EAAI'24}
}

@misc{
chao2024jailbreaking,
title={Jailbreaking Black Box Large Language Models in Twenty Queries},
author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
year={2024},
url={https://openreview.net/forum?id=hkjcdmz8Ro}
}

@misc{aijournal_moltbook_enterprise_risk_2026,
  title        = {Moltbook Showed Us the Future of Enterprise {AI} Risk. Most Companies Aren’t Ready.},
  author       = {{The AI Journal}},
  howpublished = {\url{https://aijourn.com/moltbook-showed-us-the-future-of-enterprise-ai-risk-most-companies-arent-ready/}},
  year         = {2026}
}

@misc{woods_moltbook_trending_2026,
  title        = {Moltbook: Why it's trending and what you need to know},
  author       = {Woods, Audrey},
  howpublished = {\url{https://cap.csail.mit.edu/moltbook-why-its-trending-and-what-you-need-know}},
  year         = {2026},
}

@misc{heaven_moltbook_peak_ai_theater_2026,
  title        = {Moltbook was peak {AI} theater},
  author       = {Heaven, Will Douglas},
  howpublished = {\url{https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/}},
  year         = {2026},
}

@inproceedings{choudhary2024political,
  title={Political Bias in Large Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude},
  author={Choudhary, Tavishi},
  booktitle={RAIS Conference Proceedings},
  year={2024},
  publisher={Research Association for Interdisciplinary Studies}
}

@article{hall2025partisan,
  title={Measuring Perceived Slant in Large Language Models Through User Evaluations},
  author={Sean J. Westwood and Justin Grinner and Andrew B. Hall},
  journal={Stanford Graduate School of Business Working Paper},
  year={2025},
  note={Study with 10,000+ participants evaluating 24 LLMs from 8 companies},
  howpublished={\url{https://www.gsb.stanford.edu/faculty-research/working-papers/measuring-perceived-slant-large-language-models-through-user}}
}

@misc{lynch2025agenticmisalignmentllmsinsider,
      title={Agentic Misalignment: How LLMs Could Be Insider Threats}, 
      author={Aengus Lynch and Benjamin Wright and Caleb Larson and Stuart J. Ritchie and Soren Mindermann and Evan Hubinger and Ethan Perez and Kevin Troy},
      year={2025},
      eprint={2510.05179},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2510.05179}, 
}

@misc{andriushchenko2025agentharmbenchmarkmeasuringharmfulness,
      title={AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents}, 
      author={Maksym Andriushchenko and Alexandra Souly and Mateusz Dziemian and Derek Duenas and Maxwell Lin and Justin Wang and Dan Hendrycks and Andy Zou and Zico Kolter and Matt Fredrikson and Eric Winsor and Jerome Wynne and Yarin Gal and Xander Davies},
      year={2025},
      eprint={2410.09024},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.09024}, 
}

@misc{schmotz2025agentskillsenablenew,
      title={Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections}, 
      author={David Schmotz and Sahar Abdelnabi and Maksym Andriushchenko},
      year={2025},
      eprint={2510.26328},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.26328}, 
}

@misc{kuntz2025osharmbenchmarkmeasuringsafety,
      title={OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents}, 
      author={Thomas Kuntz and Agatha Duzan and Hao Zhao and Francesco Croce and Zico Kolter and Nicolas Flammarion and Maksym Andriushchenko},
      year={2025},
      eprint={2506.14866},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2506.14866}, 
}

@misc{chen2025personavectorsmonitoringcontrolling,
      title={Persona Vectors: Monitoring and Controlling Character Traits in Language Models}, 
      author={Runjin Chen and Andy Arditi and Henry Sleight and Owain Evans and Jack Lindsey},
      year={2025},
      eprint={2507.21509},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2507.21509}, 
}

@misc{theguardianElonMusks,
	author = {Josh Taylor},
	title = {{E}lon {M}usk’s {G}rok {A}{I} tells users he is fitter than {L}e{B}ron {J}ames and smarter than {L}eonardo da {V}inci --- theguardian.com},
	howpublished = {\url{https://www.theguardian.com/technology/2025/nov/21/elon-musk-grok-ai-bias-ranks-richest-man-fittest-smartest}},
	year = {2025},
	note = {[Accessed 16-02-2026]},
}

@misc{greshake2023youvesignedforcompromising,
      title={Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection}, 
      author={Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and Christoph Endres and Thorsten Holz and Mario Fritz},
      year={2023},
      eprint={2302.12173},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2302.12173}, 
}

@article{10.1145/2844110,
author = {Diakopoulos, Nicholas},
title = {Accountability in algorithmic decision making},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/2844110},
doi = {10.1145/2844110},
abstract = {A view from computational journalism.},
journal = {Commun. ACM},
month = jan,
pages = {56–62},
numpages = {7}
}

@book{Pasquale+2015,
url = {https://doi.org/10.4159/harvard.9780674736061},
title = {The Black Box Society},
title = {The Secret Algorithms That Control Money and Information},
author = {Frank Pasquale},
publisher = {Harvard University Press},
address = {Cambridge, MA and London, England},
doi = {doi:10.4159/harvard.9780674736061},
isbn = {9780674736061},
year = {2015},
lastchecked = {2026-02-17}
}

@misc{turner2020avoidingeffectscomplexenvironments,
      title={Avoiding Side Effects in Complex Environments}, 
      author={Alexander Matt Turner and Neale Ratzlaff and Prasad Tadepalli},
      year={2020},
      eprint={2006.06547},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2006.06547}, 
}

@inproceedings{soares2015corrigibility,
  title={Corrigibility},
  author={Soares, Nate and Fallenstein, Benja and Armstrong, Stuart and Yudkowsky, Eliezer},
  booktitle={Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015},
  organization={AAAI}
}

@misc{krakovna2020avoidingeffectsconsideringfuture,
      title={Avoiding Side Effects By Considering Future Tasks}, 
      author={Victoria Krakovna and Laurent Orseau and Richard Ngo and Miljan Martic and Shane Legg},
      year={2020},
      eprint={2010.07877},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.07877}, 
}

@misc{park2023generativeagentsinteractivesimulacra,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2304.03442}, 
}

@misc{perez2022ignorepreviouspromptattack,
      title={Ignore Previous Prompt: Attack Techniques For Language Models}, 
      author={Fábio Perez and Ian Ribeiro},
      year={2022},
      eprint={2211.09527},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.09527}, 
}

@misc{owasp_llm_2025,
  author = {{OWASP Foundation}},
  title = {{OWASP Top 10 for Large Language Model (LLM) Applications - 2025}},
  year = {2025},
  month = {11},
  url = {https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf},
  note = {Accessed: 2025-02-17}
}

@misc{reuter2023ga,
      title={I'm Afraid I Can't Do That: Predicting Prompt Refusal in Black-Box Generative Language Models}, 
      author={Max Reuter and William Schulze},
      year={2023},
      eprint={2306.03423},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2306.03423}, 
}

@misc{nist2026agentstandards,
  title   = {Announcing the ``{AI} Agent Standards Initiative'' for
             Interoperable and Secure Innovation},
  author  = {{National Institute of Standards and Technology}},
  year    = {2026},
  month   = feb,
  url     = {https://www.nist.gov/news-events/news/2026/02/announcing-ai-agent-standards-initiative-interoperable-and-secure},
  note    = {Accessed February 20, 2026}
}

@misc{liu2025badworktimecrosscultural,
      title={Is It Bad to Work All the Time? Cross-Cultural Evaluation of Social Norm Biases in GPT-4}, 
      author={Zhuozhuo Joy Liu and Farhan Samir and Mehar Bhatia and Laura K. Nelson and Vered Shwartz},
      year={2025},
      eprint={2505.18322},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.18322}, 
}

@misc{li2026riseaiagentcommunities,
      title={The Rise of AI Agent Communities: Large-Scale Analysis of Discourse and Interaction on Moltbook}, 
      author={Lingyao Li and Renkai Ma and Chen Chen and Zhicong Lu and Yongfeng Zhang},
      year={2026},
      eprint={2602.12634},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2602.12634}, 
}