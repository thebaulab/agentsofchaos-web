\section{Conclusion}
This document is intended as a rapid response to the swift developments in the field of autonomous AI agents. During a two-week experimental investigation,  we identified and documented ten substantial vulnerabilities and numerous failure modes concerning safety, privacy, goal interpretation, and related dimensions. These results expose underlying weaknesses in such systems, as well as their unpredictability and limited controllability as complex, integrated architectures. The implications of these shortcomings may extend directly to system owners, their immediate surroundings, and society more broadly.
Unlike earlier internet threats where users gradually developed protective heuristics, the implications of delegating authority to persistent agents are not yet widely internalized, and may fail to keep up with the pace of autonomous AI systems development.

Who bears responsibility? The autonomous behaviors we document represent new kinds of interaction that need urgent attention from legal scholars, policymakers, and researchers across disciplines. This report is a starting point for that conversation.